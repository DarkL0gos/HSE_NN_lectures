Задача Коши для уравнения высшего порядка:
\begin{equation}
    y^{(n)} = f(t,x_1,...,x_{n-1}),~
    \begin{cases}
        x(t_{0})=x_0\\
        \dot x(t_0) = \dot x_0\\
        \vdots\\
        x^{(n-1)}(t_0)=x^{(n-1)}_0
    \end{cases}
\end{equation}
Для системы уравнений высшего порядка:
\begin{equation}\label{uvp_sist}
    \dot X = F(t,x),~x_i(t_0) = x^0_i
\end{equation}
Фазовое пространство для уравнения высшего порядка - $n$-мерное.
\begin{theor}
    (Коши - Пикара для системы уравнений высших порядков)\\
Если все $f_i,\frac{\partial t_i}{\partial x_j}$ непрерывны в области
$D\subset Otx_1...x_n$, то для любой точки для этой области решение 
задачи Коши \ref{uvp_sist} существует и единственно. 

\end{theor}
\textbf{Доказательство.}  См. Филлипов, Лерман.
$\square$ \\

\section{Линейные уравнения}
\subsection{Основные определения}
\begin{defin}
Линейное уравнение высшего порядка - уравнение вида

\begin{equation}\label{uvp_lin}
    x^{(n)}+a_1(t)x^{(n-1)}+...+a_n(t)x=f(t)
\end{equation}
где $f(t),a_i(t)$ непрерывны на  $(\alpha,\beta)$
\end{defin}
Условие непрерывности гарантирует выполнение условия для теоремы Коши-~Пикара
$\forall  t_0\in (\alpha,\beta)$. Именно, имеет место 
\begin{theor}
    (о единственности задачи Коши для \ref{uvp_lin})\\
    Если $f(t),a_1(t),...,a_n(t)$ непрерывны на  $t\in (\alpha,\beta)$,
    то для любой точки $X_0=(x_0,...,x^{(n-1)}_0)$
    фазового пространства при $t_0\in (\alpha,\beta)$
    существует единственное решение, удовлетворяющее данному начальному
    условию и определенное на интервале $ (\alpha,\beta)$.
\end{theor}
Специфика линейного уравнения состоит в продолжении решения на весь
временной промежуток.
%\textbf{Доказательство.}  
%$\square$ \\
\subsection{Свойства линейных уравнений}
Введем оператор 
$$L\colon C^n(\alpha,\beta)\to C^0(\alpha,\beta)$$
$$L = \frac{d^n}{dt^n}+a_1(t) \frac{d^{n-1}}{dt^{n-1}}+...+
a_n(t)$$
Тогда уравнение \ref{uvp_lin} имеет вид  $Lx=f(t)$. 
Свойства оператора $L$:
 \begin{enumerate}
    \item $Lkx=kLx$
    \item $L(x+y)=Lx+Ly$
\end{enumerate}
Эти свойства следуют из линейности дифференцирования, и значит, $L$ - 
линейный оператор. 
\begin{defin}
Линейное уравнение называется однородным, если оно имеет вид
\begin{equation}\label{lin_odnor}
    Lx=0
\end{equation}
\end{defin}
\begin{defin}
Линейное уравнение называется неоднородным, если оно имеет вид
 \begin{equation}
    Lx=f(t),~f(t)\not\equiv 0
\end{equation}
\end{defin}
\begin{theor} (о структуре решения)\\
Общее решение неоднородного уравнения - общее решение однородного уравнения
плюс частное решение неоднородного уравнения. 
\end{theor}
\textbf{Доказательство.}  
$\square$ 

Подбор частного решения: метод вариации постоянных Лагранжа, формула Коши.
Сравнимая по сложности задача - поиск решения однородного уравнения.
\subsection{Линейное однородное уравнение}
Непосредственно проверяется, что множество решений уравнения \ref{lin_odnor} -
векторное пространство. Оказывается, его размерность равна порядку 
максимальной производной.
\begin{defin}
Функции $x_i(t)$ называются линейно зависимыми, если существует нетривиальный
набор констант  $c_i$, что для всех $t\in (\alpha,\beta)$
$$\sum\limits_{i=1}^{n} c_ix_i(t)=0$$
Тогда этот интервал называется интервалом линейной зависимости.\\
В противном случае набор функций наывается линейно зависимым. 
\end{defin}
\textbf{Пример.} $x_1=t,x_2=1$ - линейно независимы. Предположим противное, 
а именно при $t\in (-\infty,\infty)$ $\exists  c_1,c_2:c_1^2+c_2^2\ne 0$, и
$c_1t+c_{2}1=0$. Но тогда $c_1=c_2=0$ - противоречие. \\
\textbf{Пример.} $x_1=t,x_2=2t$ - линейно зависимы.\\
\textbf{Пример.} $x_1=t^2,x_2=t^2+2$ - линейно независмы.\\
Очевидно, добавление нуля к системе гарантированно делает её линейно зависимой.
\begin{defin}
    Вронскиан (определитель Вронского) $C^{n-1}$-дифференцируемых функций
     $x_1(t),...,x_n(t)$ - определитель матрицы
\end{defin}
\begin{equation}
    W(x_1,...,x_n) = \begin{vmatrix}
        x_1(t) & ... & x_n(t) \\
        \dot x_1(t) & ... & \dot x_n(t) \\
        \vdots & & \vdots \\
        x_1^{(n-1)}(t) & ... & x_n^{(n-1)}(t)
    \end{vmatrix} 
\end{equation}
Например, $W(\sin t, \cos t)=\begin{vmatrix} \sin t &\cos t\\ \cos t&-\sin t
\end{vmatrix} = -1$
\begin{theor}
    (необходимое условие линейной зависимости функций)\\
    Если $C^{n-1}$-дифференцируемые функции линейно зависимы, то их вронскиан
    тождественно равен нулю.
\end{theor}
\textbf{Доказательство.}  Пусть $x_1(t),...,x_n(t)$ - линейно зависмые 
функции. Тогда существует нетривиальный набор констант такой, что
$$c^ix_i(t)=0$$ 
Дифференцируя это равенство, будем получать
\begin{equation} \label{w_sist}
  \begin{cases}
    c_1x_1(t)+...+c_nx_n(t)=0\\
    c_1\dot x_1(t)+...+c_n\dot x_n(t)=0\\
    ...\\
    c_1x^{(n-1)}_1(t)+...+c_nx^{(n-1)}_n(t) = 0
\end{cases}  
\end{equation}
Пусть $t=t^*$. Тогда $x^{(k)}_i=const$, и для этого 
 $t^*$ система \ref{w_sist} - СЛАУ относительно $c_i$. Так как имеется 
нетривиальное решение,её определитель 0.

Приведем пример системы линейно независимых функций с нулевым 
вронскианом. Положим
$x_1=\begin{cases}   t^2,t\geqslant 0\\0,t<0 \end{cases},
x_2=\begin{cases} 0,t\geqslant 0\\t^2,t\leqslant 0 \end{cases}$.
Легко проверить, что эти функции дифференцируемы всюду на прямой. Имеем 
вронскиан $W(x_1,x_2)\equiv0$. Докажем линейную независимость. Допустим, 
существует неривиальная линейная комбинация $c^ix_i(t)=0$. Но тогда 
$c^i=0$. $\square$ \\

\begin{theor}
Пусть $x_1(t),...,x_n(t)$ - решения линейного однородного уравнения. Тогда:\\
1. Если  $\exists  t^*:W(x_1(t^*),...,x_n(t^*))\ne0$, то
$x_1(t),...,x_n(t)$ линейно независимы (и вронскиан в любой точке $t$ не 
равен 0).\\
2. Если $\exists t_0:W(x_1(t_0),...,x_n(t_0))=0$, то $x_1(t),...,x_n(t)$
линейно зависимы, и вронскиан тождественно равен нулю. 
\end{theor}
\textbf{Доказательство.}  
1. То, что не в скобках, следует из необходимого условия линейной 
зависимости.\\
2. Выпишем $i$-тый столбец вронскиана:
 $$X_i(t_0)=\begin{cases}
     x_i(t_0)\\x'_i(t_0)\\...\\x^{(n-1)}_i(t_0)
 \end{cases}$$
По условию, вронскиан равен нулю, значит, существует нетривиальная 
линейная комбинация столбцов $\sum\limits_{i=1}^{n} c_iX_i(t_0)=0$. 

Положим $X(t) = \sum\limits_{i=1}^{n} c_iX_i(t)$. Тогда 
$X(t_0)=(0,...,0)^T$. Подействуем линейным оператором уравнения на этот вектор:
$$LX(t)=L\left(  \sum\limits_{i=1}^{n} c_iX_i(t)\right) = 
\sum\limits_{i=1}^{n} c_i\cdot LX_i(t)$$
Поскольку $x_i(t)$ - решения, то  $L(X_i(t))\equiv 0$, откуда $LX(t)\equiv0$ - 
то есть, $X(t)$ - решение уравнения  $Lx=0$ с нулевым начальным условием.
С другой стороны, это уравнение имеет решение с нулевым начальным 
условием: $x(t)\equiv 0$. Значит, по теореме о существовании и 
единственности имеем $\sum\limits_{i=1}^{n} c_ix_i(t)=0$ 
$\forall  t\in (\alpha,\beta)$, поэтому $x_1,...,x_n$ линейно зависимы. 

Предположим, что существуют $t_1,t_2\in (\alpha,\beta):
W(x_1(t_1),...,x_n(t_1))\ne 0,W(x_1(t_2),...,x_n(t_2))=0$. 
Но по только что доказанному свойству, из существования $t_2$ следует,что 
$W(t)=0$ при $t\in (\alpha,\beta)$. 
$\square$ 


\textbf{Следствие.} Не существует линейного однородного уравнения, решениями
которого были бы функции 
$x_1=\begin{cases}   t^2,t\geqslant 0\\0,t<0 \end{cases},
x_2=\begin{cases} 0,t\geqslant 0\\t^2,t\leqslant 0 \end{cases}$. 
\begin{theor}
Существует набор линейно независимых решений $x_1(t),...,x_n(t)$, такой что
все решения уравнения $Lx=0$ имеет вид  $x=\sum\limits_{i=1}^n c_ix_i(t)$, то 
есть пространство решений является $n$-мерным векторным пространством. 
\end{theor}
\textbf{Доказательство.}  Рассмотрим набор линейно независимых 
векторов $X_i=$(..0,единица на $i$-м месте,0...$)^T$. Поставим $n$ задач
Коши типа
$\begin{cases}
    Lx_i=0\\
    X_i = 
    \begin{pmatrix} x_i(t_0)\\x'_i(t_0)\\ \vdots x^{(n-1)}_i(t_0)\end{pmatrix} 
\end{cases}$
По теореме едиснвтенности, имеется $n$ единственных решений этих задач. 
Решения линейно независимы, так как
$$W(x_1(t_0),...,x_n(t_0))=\Big|X_1,...,X_n\Big|\ne 0$$ 
а исходные столбцы линейно независимы. Так как все остальные векторы
выражаются через этот базис, то это - максимально линйено независимая
подсистема $\Rightarrow$ это пространство $n$-мерное. $\square$ 

\subsection{Формула Остроградского-Лиувилля}




\subsection{Практика}

\textbf{№663.а} Допустим, $x_1=const$. Тогда
    $W(x_1,x_2,x_3)=\begin{vmatrix} 1&x_2&x_3\\0&x'_2&x'_3\\0&x''_2&x''_3
    \end{vmatrix} = x'_2x''_3-x'_3x''_2$. Обе функции возрастают, но у них
    разные выпуклости: поэтому в точке $t^*$, лежащей за точкой 
    перегиба $x_2,x_3,x''_3>0$, но $x''_2<0$, значит, $W|_{t^*}>0$.
Но тогда вронскиан не зануляется на всем промежутке (почему?). 

\textbf{№668.} Пусть $x_1,x_2$ - решения уравнения $\ddot x+p(t)\dot x+q(t)=0$.
Докажем, что если они имеют максимум в одной точке, то они линейно
зависимы. Имеем в этой точке
$$W|_{t^*}=\begin{vmatrix} x_1(t^*) & x_2(t^*) \\ 0&0 \end{vmatrix}=0$$
Значит, система линейно зависима.


\textbf{№669.} Имеем вронскиан $3\times 3$ с линейно зависимыми первой строкой 
(функции) и второй строкой (производные). Поэтому он нулевой. Значит, любые
три решения линейно зависимы. Верхняя оценка для количества линейно 
независимых решений - 2. Теперь рассмотрим решения 
$u_1=y_1-y_2,u_2=y_2-y_3,u_3=y_3-y_4$. Имеем $u_1(t^*)=0,u'_1(t^*)=0$, но
может быть так, что $u''_1(t^*)=\alpha$ - в дз %епта.

\textbf{№677.} Чтобы составить уравнение, надо понять, являются ли эти 
решения линейно зависимы. В базисе многочленов имеем систему
$\begin{pmatrix} 1&-3&0\\2&0&9\\0&2&3\end{pmatrix}$, которая линейно зависима.
Значит, они не образуют базис в пространстве решений уравнения порядка 3. 
Порядок уравнения не больше 2. Но там есть 2 линейно независимых многочлена,
поэтому может быть уравнение второго порядка. Запишем вронскиан:
$$W=det\begin{pmatrix} y_2&y_3&u\\y'_2&y'_3&u'\\y''_2&y''_3&u''\end{pmatrix}
=0$$
Это и будет искомое линейное уравнение на функцию $u=u(x)$. 

%дз 669 Юра, 670 Рома, 663б 664 678 

\textbf{Другая практика}

\section{Линейное неоднородное уравнение}
Пусть 
\begin{equation}
    x^{(n)} + a_1(t)x^{(n-1)}+...+a_n(t) = f(t)
\end{equation}
- линейное неоднородное уравнение, $x_1,...,x_n$ - 
линейно независимые частные решения однородного уравнения. 
Значит, общее решение однородного уравнения имеет вид
$$\sum\limits_{i=1}^{n} c_ix_i(t)$$ 
\begin{theor}
Существует такое набор функций $c_i(t)$, что 
частное решение неоднородного уравнения имеет вид 
\end{theor}
$$x_\text{ч.н.} = \sum\limits_{i=1}^{n} c_i(t)x_i(t)$$
\textbf{Доказательство.}  Положим $\sum\limits_{i=1}^{n} \dot c_ix^{(j)}_i=0$,
где $0\leqslant j\leqslant  n-2$, и
$\sum\limits_{i=1}^{n} \dot c_i x^{(n-1)}_i = f(t)$. 
Эти условия задают задают линейную систему относительно $\dot c_i$ Определитель
этой системы - вронскиан:
$$\Delta = det\begin{pmatrix} x_1 & ... & x_n \\
\vdots &&\vdots \\ x^{(n-1)}_1 &...& x_n^{(n-1)} \end{pmatrix}  = 
W (X_1(t),...,X_n(t))\ne 0$$
Эта система имеет единственное решение $\dot c_i = \frac{\Delta_i}{\Delta}$.
Тогда получаем
$$c_i = 
\int\limits_{t_0}^{t}\frac{\Delta_i(\tau)}{\Delta(\tau)}d\tau + c_i(t_0)$$

Тогда $$\dot x = \sum\limits_{i=1}^{n} \dot c_ix_i +
\sum\limits_{i=1}^{n} c_i\dot x_i = 0 + \sum\limits_{i=1}^{n} c_i\dot x_i$$
$$\ddot x = \sum\limits_{i=1}^{n} c_i \ddot x_i$$

$$...$$ 

$$x^{(n-1)}=\sum\limits_{i=1}^{n} c_i x^{(n-1)}_i$$
$$x^{(n)} = \sum\limits_{i=1}^{n} \dot c_i x^{(n-1)}_i + 
\sum\limits_{i=1}^{n} c_i x^{(n)}_i$$
Складывая эти выражения, домноженные на коэффициенты уравнения, получаем
$$\sum\limits_{i=1}^{n} c_i (a_n)$$
$\square$ 


\section{Линейные уравнения с постоянными коэффициентами}
\begin{equation}
    \label{lop}
    x^{(n)} + a_1x^{(n-1)} + ... +a_nx = 0,~a_i=const
\end{equation}
\textbf{Пример.} $\ddot x- 5\dot x + 6x = 0$. Используем подстановку 
Эйлера: ищем частное решение в виде $x=e^{\lambda t}$. Имеем
$\dot x = \lambda e^{\lambda x}$, $\ddot x = \lambda^2 e^{\lambda t}$. 
Получаем характеристическое уравнение 
$$\lambda^2 - 5\lambda + 6 = 0$$
чьи корни $\lambda_{1,2}=2,3$. Значит, базис в прсотранстве
решений: $x_1=e^{2t}$, $x_2=e^{3t}$. Проверим, что это действительно
баси, составив вронскиан и проверив линейную независимость: 
    $$W(x_1,x_2)\Big|_{t=0}=det \begin{pmatrix} 1 & 1 \\ 2 & 3 \end{pmatrix}
    \ne 0$$ 
Пишем ответ: $x=C_1e^{2t} + C_2e^{3t}$ 

Вообще говоря, будем искать частное решение уравнения \ref{lop} в виде
$x = e^{\lambda t}$. Имеем
\begin{equation}\label{xar_ur}
    L(e^{\lambda t}) = e^{\lambda t}(\lambda^n+a_1\lambda^{n-1}+...+a_n) =
    e^{\lambda t}\chi(\lambda) = 0
\end{equation}
То есть при $e^{\lambda t}\ne 0$, уравнения $L(e^{\lambda t})=0$ и
 $\chi(\lambda)=0$ эквивалентны.
\begin{defin}
    Уравнение \ref{xar_ur} называется характеристическим уравнением. 
\end{defin}
\textbf{Случай 1}. Все корни характеристичсекого уравнения различны. 
Допустим, что эти частные решения $x_1=e^{\lambda_1t},...,x_n=e^{\lambda_nt}$ 
линейно независимы: 
    $$W({x_1,...,x_n})|_{t=0} = det\begin{pmatrix} 1&...&1\\
        \lambda_1&...&\lambda_n\\ \vdots&&\vdots \\
        \lambda^{n-1}&...&\lambda^{n-1}


    \end{pmatrix}\ne 0 $$
Тогда определитель - опреелитель Вандермонда, равный 
$\prod\limits_{i<j}^{n} (\lambda_i-\lambda_j)\ne 0 $


\textbf{Случай 2.} Пусть есть кратные корни, то есть 
$\lambda_1,...,\lambda_s,s<n$ - различные корни с кратностями
$k_1,..,k_s$. Тогда $x_1=e^{\lambda_1t},...,x_s=e^{\lambda_st}$ - 
решения уравнения $Lx=0$. Но по теореме о структуре решения, этого не 
достаточно для $n$-мерного базиса. Дополним до фундаментальной системы 
решений квазиполиномами. Именно, имеет место 
\begin{theor}
Пусть $\lambda$ - корень кратности $k$. Тогда 
$e^{\lambda t},te^{\lambda t},...,t^{k-1}e^{\lambda t}$ - решения 
уравнения $Lx=0$.  
\end{theor}
\textbf{Доказательство.}  

Пусть $\lambda\in \{\lambda_1,...,\lambda_s\}$. Рассмотрим 
$x=t^me^{\lambda t}$. По обобщенной формуле Лейбница для высших производных
произведения, получаем
$$\frac{d^\nu x}{dt^\nu} = \sum\limits_{i=0}^{\nu} C^i_\nu \cdot 
(t^m)^{(\nu - i)}\cdot (e^{\lambda t})^{(i)}$$ 
(доказать можно по индукции, как и бином). 

Заметим, что 
$$t^ke^{\lambda t} = \frac{d^{k}(e^{\lambda t})}{d\lambda^{k}}$$
Отсюда получаем 
$$\frac{d^\nu }{dt^\nu}(t^me^{\lambda t}) = 
\frac{\partial^{\nu+m} (e^{\lambda t})}{\partial t^\nu \partial\lambda^m} $$
Теперь подставим квизимногочлен в уравнение:
$$L(t^me^{\lambda t}) = x^{(n)}+\sum\limits_{i=1}^{n} a_ix^{(n-i)} = 
(t^me^{\lambda t})^{(n)}_t+\sum\limits_{i=1}^{n} 
a_i(t^me^{\lambda t})^{(n-i)}_t=$$
Пользуясь нашим замечанием, имеем
$$=\big(\Big(e^{\lambda t}\Big)^{(m)}_\lambda\big)^{(n)}_t + 
\sum\limits_{i=a}^{n} a_i((e^{\lambda t})^{(m)}_\lambda)^{(n-i)}_t=$$
Поменяем местами порядок дифференцирования, и тогда получим
$$=L(e^\lambda t)^{(m)}_\lambda = (e^{\lambda t}\cdot 
\chi(\lambda))^{(m)}_\lambda = $$ 
Пользуясь формулой Лейбница, получаем
$$=\sum\limits_{j=1}^{m} C^j_m\chi^{(j)}_\lambda(e^{\lambda t})^{(m-j)}_\lambda
= \sum\limits_{j=1}^{m} C^j_m\chi^{(j)}_\lambda t^{m-j}e^{\lambda t}$$
причем это тождественно равно нулю для всех $m$, меньших кратности  $\lambda$. 
$\square$

\begin{theor}
Пусть $\lambda_1,...,\lambda_s$ - корни кратности $k_1,...,k_s$. Тогда


$e^{\lambda_1 t},te^{\lambda_1 t},...,t^{k_1-1}e^{\lambda_1 t},...,
e^{\lambda_2 t},te^{\lambda_2 t},...,t^{k_2-1}e^{\lambda_2 t},...,
t^{k_{s}-1}e^{\lambda_st}$ - линейно независимые решения уравнения $Lx=0$. 
\end{theor}
\textbf{Доказательство.}  Допустим противное. Пусть существует нетривиальный
набор $c_1,...,c_n$, что $c_1e^{\lambda_1t}+...+c_nt^{k_s-1}e^{\lambda_st}$. 
Для каждого $\lambda_i$ вынесем экспоненту, тогда получим
$$e^{\lambda_1t}P_{k_1-1}(t)+...+e^{\lambda_st}P_{k_s-1}(t)=0$$
Так как комбинация ненулевая, то хотя бы один из полиномов 
$P_i$ не равен нулю. Без ограничения общности положим 
$P_{k_1-1}(t) = c_1+c_2t+...+c_{k_1}t^s\not\equiv$. 
Домножим комбинацию многочленов на $e^{-\lambda_st}$ и продифференцируем 
$k_s$ раз, чтобы занулить последний многочлен:
$$\frac{d^{k_s}}{dt^{k_s}}(e^{\lambda_1t}P_{k_1-1}(t)+
...+e^{\lambda_st}P_{k_s-1}(t)) = $$ 
\textbf{Упражнение.} $\frac{d^s}{dt^s}(e^{\alpha t}t^k) = $  \\
Значит, е не обнулилось, но тогда многочлен нулевой - противоречие с условием.

\subsection{Овеществление решений}
Пусть $\lambda = \alpha+i\beta$ - корень уравнения 
\ref{xar_ur}. Тогда автоматически $\lambda = \alpha + i\beta$ - такжа корень.
Тогда
$x_{1,2}=t^se^{\alpha\pm i\beta}=t^se^{\alpha t}(\cos\beta t\pm i\sin\beta t)$.
Каждой такой паре сопоставим вещественные решения 
$y_1=\frac{x_1+x_2}{2},y_2=\frac{x_1-x_2}{2i}$, - линейные комбинации старых. 
Теперь можнозаписать новую ФСР:
$$\begin{cases}
    y_1 = t^se^{\alpha t}\cos\beta t\\ 
    y_2 = t^se^{\alpha t}\sin\beta t
\end{cases}$$ 
Проверим, что новая система линейно независима:
        $$detW(y_1,y_2)=detW(x_1,x_2)\cdot 
        \begin{pmatrix} \frac{1}{2} & \frac{1}{2i} \\
            \frac{1}{2} & -\frac{1}{2i} 
        \end{pmatrix} $$
Это можно по индукции продолжить на $n$ переменных. и эти определители
ненулевые. $\square$ \\
%РАССКАЗАТЬ ПРО ПОНИЖЕНИЕ ПОРЯДКА - прочитать самим потому что Рома задушнил

\subsection{Подбор частного решения неоднородного уравнения по виду 
правой части}

\begin{theor}
Пусть $L$ - оператор с постоянными коэффициентами,  $x_1,x_2$ - решения 
уравнений $Lx_1=f_1(t),L(x_2)=f_2(t)$. Тогда
$x=x_1+x_2$ - решение уравнения $Lx = f_1+f_2$. 
\end{theor}
\textbf{Доказательство.} Используя линейность оператора, имеем
$L(x_1+x_2)=f_1+f_2$. $\square$ 

Таким образом, мы свели к случаю, когда в правой части одно слагаемое. 
Пусть правая часть - квазиполином:
\begin{equation}\label{q-pol}
    Lx = e^{\alpha t}p_m(t),~p_m = b_0t^m + b_1t^{m-1} + ... +b_m
\end{equation}
\begin{theor}  (Арнольд \S 26.5)\\
    Eсли $\alpha$ является корнем характеристчисекого уравнения и $\beta$ - 
его кратность (если не корень, положим  $\beta = 0$).  уравнение
\ref{q-pol} имеет решение в виде  $x_\text{ч.р.} = e^{\alpha t}q_m(t)t^\beta$,
где $q_m(t)=g_0t^m + g_1t^{m-1}+...+g_m$.
\end{theor}
\textbf{Пример.} $\ddot x - 2\dot x + x = e^t$. Имеем  $\lambda_{1,2}=1$.\\
\textbf{Пример.} $\ddot x - 2\dot x + x =\cos t$ - уравнение 
вынужденных колебаний. Фокус: рассмотрим уравнение
$\ddot x - 2\dot x + x = e^{it}$. Тогда  $x_\text{ч.р.}=Re(g_0e^{it})$\\
\textbf{Доказательство.}  Пусть $x = e^{\alpha t}t^\beta g_0 t^m$. 
Подставим в уравнение: $x = g_0e^{\alpha t}t^{\beta +m} = g_0(e^{\alpha t})^{
    \beta +m}_\alpha$. 
Получаем
$$L(x) = x^{(n)} + \sum\limits_{i=1}^{n} a_i(t)x^{(n-i)}_t$$ 
Меняя порядок дифференцирования по $\alpha$ и $t$, имеем
$$\bigg(L(g_0e^{\alpha t})\bigg)^{(\beta +m)}_\alpha = 
g_0(e^{\alpha t}\chi(\alpha))^{\beta + m}_\alpha = 
g_0 \sum\limits_{i=0}^{\beta + m} C^i_{\beta + m}\chi^{(i)}_\alpha
t^{\beta + m -i}e^{\alpha t}
$$
Найдем старшую степень $t$, при которой стоит ненулевой коэффициент.
Рассмотрим 2 случая.\\
1. 
Если $\chi(\alpha)\ne 0,\beta = 0$. Тогда
при $i=0$ имеем  $g_0\chi^{(0)}_\alpha t^m$, и коэффициент не равен
нулю, $t^m$ - старшая степень. \\
2. Если $\chi(\alpha) = 0,\beta = k$. Тогда
при $i=\in \{0,...,k-1\}$ имеем $\chi^{(i)}_\alpha = 0$, при 
$i = k:e^{\alpha t}g_0 C^k_{\beta + m}\chi^{(k)}_\alpha(\alpha)t^{k+m-k}$. 
Получаем
$$L(e^{\alpha t}t^\beta g_0 t^m) = \begin{cases}
    e^{\alpha t}(g_0\chi(\alpha)t^m + r_{m-1}(t)) \\
    e^{\alpha t}(g_0C^k_{\beta + m}\chi^{(k)}(\alpha)_\alpha t^m + r_{m-1}(t))
\end{cases} \equiv e^{\alpha t}p_m(t)$$
Пусть $m = 0$ (тогда $r_{m-1}(t) = 0$). 
$g_0 = \frac{b_0}{\chi(\alpha)}$, если $\beta = 0$;\\
$x_\text{ч} = $
$$L(e^{\alpha t}g_0 t^{m+\beta} + z(t)) = $$


аналогично $\beta > 0$. 

$\square$ \\
\textbf{Утверждение.} Пусть $x = u(t) + iv(t)$ - решение уравнения
 $L(x) = f(t) + ig(t)$ (функции и оператор - вещественные). 
 Тогда  $u(t),v(t)$ - решения уравнений 
$L(x) = f(t),L(x) = g(t)$ соответсвенно. Доказательство - по линейности 
оператора.

\textbf{Пример.} $\ddot x + 25x = \cos t$. Вспоминаем формулу Эйлера и 
решим уравнение $\ddot x + 25x = e^{it}$. По только что доказанной теореме
ищем частное решение в виде $x_\text{ч.р.} = e^{it}g_0$. Дифференцируя, 
получаем $\ddot x = -e^{it}g_0$, откуда $g_0 = \frac{1}{24}$. 
$x_\text{ч.р.} = \frac{1}{24}e^{it} = \frac{1}{24}(\cos t + i\sin t)$.
Применяя утверждение, получаем решение исходного уравнения 
$x = Re \frac{1}{24}e^{it}$.

\textbf{Пример.} $\ddot x + x = \cos t$. Корни харктеристического
уравнения $\lambda = \pm i$. Решать как в прошлом примере нельзя, так как
$-g_0 + g_0 = 1$. А надо правильно применять теорему и утверждение! $g_0$-то
у нас комплексное! Получаем $g_0 = \frac{1}{2i} = -\frac{i}{2}$. 
%жду ответа, как соловей лета

\subsection{Приложение: колебания лийненого осцилятора}
Арнольд \S 26.6\\
Запишем уравнение маятника с трением
$m\ddot x = mg - F_\text{упр} - F_\text{трения}$.
Применим закон Гука:
$m\ddot x = mg - k(l-x) - h\dot x$ (сила трения пропорциональна скорости).
Приведем к нормальнмоу виду:
$$\ddot x + \frac{h}{m}\dot x + \frac{k}{m} x = g + \frac{kl}{m}$$
























\newpage
\subsection{Практика} %04.02.2023

\textbf{№701.} $y'''+a_1(t)y''+...+a_3(t)y=0$ c частными решениями 
$y_1=x_1,y_2=\frac{1}{x}$. Как решать уравнение третьего порядка?
Ввести замену $y(x)=u(x)y_1$. Получим уравнение 
$$u''+b_1(t)u'+b_2(t)u=0$$
$y_2=u_\text{частное}y_1$, $u=t(x)u_\text{частное}=$

Сведено к формуле Остроградского-Лиувилля (чьтооо)

\textbf{№524.} $y^V-6y^{IV}+9y'''=0$ - уравнение типа \ref{lop}.
Ищем решение в виде $x_i = e^{\lambda t}$. 
Характеристическое уравнение $\lambda^3(\lambda-3)^2=0$,
корни $\lambda_{1,2,3}=0,\lambda_{4,5}=3$. \\
\textbf{Ответ:} $x(t)=C_1\cdot 1+
C_2\cdot t+C_3\cdot t^2+C_4e^{3t}+C_5te^{3t}$. 

\textbf{№517.} $y''+4y=0$. Характеристчисекий многочлен  $\lambda^2+4=0$,
корни $\lambda=\pm 2i$. Запишем ФСР: 
$y_1=e^{2ix},y_2=e^{-2ix}$.\\
\textbf{Ответ:} $y(x) = C_1e^{2ix} + C_2e^{-2ix}$.
Ответ комплексный, что может вызвать нарекания со стороны физически
настроенных людей. Договоримся, что если коэффициенты уравнения 
действительные, то мы будем рассматривать только действительнозначные 
решения типа $\mathbb{R}\to \mathbb{R}$ (поэтому нельзя прятать 
$i$ в константы интегрирования). 

Проведем овеществление этого решения. Вспоминаем формулу Эйлера:
$$\boxed{e^{\alpha+i\varphi}=e^\alpha(\cos\varphi+i\sin\varphi)}$$ 
Тогда имеем
$$y_1=e^{2ix}=\cos 2x + i\sin2x,~y_2=e^{-2ix}=\cos 2x -i\sin 2x$$
Перейдем к базису, в котором не будет комплексных чисел:
$$y'_1=\frac{y1+y_2}{2}=\cos 2x,~y'_2 = \frac{y_1-y_2}{2} =\sin 2x$$
Проверяя вронскиан, убеждаемся, что эти функции - также фундаментальная
линейно независимая система решений. Поэтому альтернативная форма ответа:
$y(x) = C_1\cos 2x + C_2\sin 2x$. 



\textbf{№518.} $y'''-8y=0$. Характеристическое уравнение 
$\lambda^3 - 8 = 0$. Корни: $$\lambda_1 = 2,~\lambda_{2,3} = 
\cos\Big(\frac{2\pi}{3}\Big)\pm i\sin\Big(\frac{2\pi}{3}\Big)=-1\pm i\sqrt{3}$$
Запишем ФСР бесплатную (прямо из решения) и овеществленную:
$$\begin{cases}
    e^{2x} \\ e^{(-1+i\sqrt{3})x} \\ e^{(-1-i\sqrt{3})x} \end{cases} = 
\begin{cases}
    e^{2x} \\ e^{-x}\cos(\sqrt{3}x) \\ e^{-x}\sin(\sqrt{3}x)
\end{cases}$$
\textbf{Ответ:} $y(x) = 
C_1e^{2x} + C_2e^{-x}\cos(\sqrt{3}x)+C_3e^{-x}\sin(\sqrt{3}x )$


\textbf{№531.} $y'''-3y'+2y = 0$. 
Характеристическое уравнение: $\lambda^3-3\lambda+2=0$. 
Корни: $\lambda_{1,2}=1,\lambda_3=-2$.\\
\textbf{Ответ:} $y=C_1e^{x}+C_2te^{x}+C_3e^{-2x}$. 

\textbf{№577.} Линейное неоднородное уравнение $y'' = y = \frac{1}{\sin x}$. 
Решим методом вариации постоянных. Сначала - общее решение 
однородного уравнения: $y(x)= C_1\cos x + C_2 \sin x$. 
Считая, что $C_1,C_2$ - функции от $x$, получаем уравнение
$$ = \frac{1}{\sin x}$$ 


Занулили $C'_1(x)\cos x + C'_2(x)\sin x = 0$, потому что захотели.

Получаем 
$$C_2(x)=\int\limits_{}^{}\frac{\cos }{\sin x}dx = \ln|\sin x|+C^*_2$$


    ?????????????????????????????
ищем частное, а получаем общее лол\\
\textbf{Ответ:} $y(x) = (-x+C^*_1)\cos x + (\ln|\sin x| + C^*_2)\sin x$.

\textbf{Практика 18.02.23}

\textbf{№546.} $y''+y=x\sin x$. $\lambda^2 + 1 = 0$, 
$\lambda = \pm i$. ФСР для однородного уравнения:
$\{\cos x,\sin x\},y = C_1\cos x + C_2\sin x$. Применяя теорему о 
квазиполиномах, ищем частное решение уравнение $y''+y=xe^{ix}$ в виде 
$y = e^{ix}(g_0x+g_1)x$. Дифференцируя и подставляя в уравнение,  
получаем $y = e^{ix}(-\frac{1}{4}ix + \frac{1}{4})x$. А мы хотим вщественную 
часть. Ответ: $y = C_1\cos x + C_2\sin x +\frac{1}{4}(-x^2\cos x+x\sin x)$. 


\textbf{№549.} $y''-2y'+2y = e^x + x\cos x$. 
Имеем $\lambda^2-2\lambda + 2 = 0$. $\lambda = 1 \pm i$. 
В правой части - сумма двух квазиполиномов. Поэтому будем искать отдельно.
Для экспоненты $y_1=e^xg_0$. Для косинуса: $y''-2y'+2y = xe^{ix}$ (потом
возьмем вещетсвенную часть):  $y_2 = e^{ix}(\tilde g_0x+\tilde g_1)$ 
(вообще говоря, $\tilde g_0,\tilde g_1\in \mathbb{C}$). Ну типа
$y_2 = (\cos x +i\sin x)(a_0x+ib_0x+a_1+ib_1)$ (чтобы не облажаться с поиском
вещественной части.)
Ответ: $y=(a_0x+a_1)\cos x+(\tilde b_0x+\tilde b_1)\sin x + e^xg_0$. 

\textbf{№5} $y''' + y' = \sin x + x \cos x$. 
$\lambda^3+\lambda =0$.
$\lambda_1=0$, $\lambda_{1,2} = $








